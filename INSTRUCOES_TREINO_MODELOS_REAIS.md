# Instru√ß√µes para Treinar Modelos Light REAIS

**Data:** 2026-01-28
**Arquivo de dados:** `lineups_previstos/lineup_history.parquet` (40KB)
**Objetivo:** Substituir modelos MOCK por modelos treinados com dados reais

---

## üìã Pr√©-requisitos

### 1. Depend√™ncias Python

```bash
pip install pandas>=1.5.0 pyarrow lightgbm>=3.3.0 scikit-learn>=1.0.0 numpy
```

### 2. Arquivo de Dados

‚úÖ **J√° existe:** `lineups_previstos/lineup_history.parquet` (40KB)

---

## üîç PASSO 1: Analisar Dados Dispon√≠veis

Execute o script de an√°lise para verificar a estrutura dos dados:

```bash
cd /home/user/previsao_filas
python3 analise_dados_historicos.py
```

**O que este script faz:**
- Carrega o arquivo parquet
- Lista todas as colunas dispon√≠veis
- Verifica quais das 15 features necess√°rias est√£o presentes
- Mostra estat√≠sticas do target (tempo_espera_horas)
- Indica se h√° dados suficientes para treino

**Output esperado:**
```
üìä Informa√ß√µes B√°sicas:
   Linhas: X,XXX
   Colunas: XX

‚úÖ Features Necess√°rias para Modelo Light (15):
   ‚úÖ navios_no_fundeio_na_chegada    X/X (XX%)
   ‚úÖ porto_tempo_medio_historico      X/X (XX%)
   ...

üí° Recomenda√ß√µes:
   ‚úÖ Dados suficientes para treinar (XX/15 features)
```

---

## üöÄ PASSO 2: Treinar Modelos Light

Depois de confirmar que h√° dados suficientes, execute o script de treino:

```bash
python3 pipelines/train_light_models_real.py
```

### Script de Treino (`train_light_models_real.py`)

Crie o arquivo `pipelines/train_light_models_real.py` com o c√≥digo abaixo:

```python
#!/usr/bin/env python3
"""
Script para treinar modelos light REAIS com dados hist√≥ricos.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json
from datetime import datetime
import pickle
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Features por perfil
FEATURES_LIGHT = {
    "VEGETAL": [
        "navios_no_fundeio_na_chegada",
        "porto_tempo_medio_historico",
        "tempo_espera_ma5",
        "navios_na_fila_7d",
        "nome_porto",
        "nome_terminal",
        "natureza_carga",
        "movimentacao_total_toneladas",
        "mes",
        "periodo_safra",
        "dia_semana",
        "flag_soja",
        "flag_milho",
        "precipitacao_dia",
        "vento_rajada_max_dia",
    ],
    "MINERAL": [
        "navios_no_fundeio_na_chegada",
        "porto_tempo_medio_historico",
        "tempo_espera_ma5",
        "navios_na_fila_7d",
        "nome_porto",
        "nome_terminal",
        "natureza_carga",
        "movimentacao_total_toneladas",
        "mes",
        "dia_semana",
        "precipitacao_dia",
        "vento_rajada_max_dia",
        "temp_media_dia",
        "tipo_navegacao",
        "ais_fila_ao_largo",
    ],
    "FERTILIZANTE": [
        "navios_no_fundeio_na_chegada",
        "porto_tempo_medio_historico",
        "tempo_espera_ma5",
        "navios_na_fila_7d",
        "nome_porto",
        "nome_terminal",
        "natureza_carga",
        "movimentacao_total_toneladas",
        "mes",
        "periodo_safra",
        "dia_semana",
        "precipitacao_dia",
        "vento_rajada_max_dia",
        "tipo_navegacao",
        "dia_do_ano",
    ],
}


def load_historical_data():
    """Carrega dados hist√≥ricos."""
    parquet_file = Path("lineups_previstos/lineup_history.parquet")

    if not parquet_file.exists():
        raise FileNotFoundError(f"Arquivo n√£o encontrado: {parquet_file}")

    df = pd.read_parquet(parquet_file)
    print(f"‚úÖ Dados carregados: {len(df):,} registros, {len(df.columns)} colunas")

    return df


def train_light_model(profile, X_train, y_train, X_val, y_val, X_test, y_test):
    """Treina modelo light para um perfil."""
    print(f"\n{'='*60}")
    print(f"Treinando modelo LIGHT REAL: {profile}")
    print(f"{'='*60}")
    print(f"Features: {len(X_train.columns)}")
    print(f"Train: {len(X_train):,} | Val: {len(X_val):,} | Test: {len(X_test):,}")

    # LightGBM Regressor
    lgb_reg = lgb.LGBMRegressor(
        n_estimators=200,
        max_depth=8,
        learning_rate=0.05,
        num_leaves=31,
        min_child_samples=20,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1,
        verbose=-1,
    )

    lgb_reg.fit(
        X_train,
        y_train,
        eval_set=[(X_val, y_val)],
        eval_metric="mae",
        callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)],
    )

    # LightGBM Classifier
    y_train_class = pd.cut(y_train, bins=[0, 48, 120, 10000], labels=[0, 1, 2])
    y_val_class = pd.cut(y_val, bins=[0, 48, 120, 10000], labels=[0, 1, 2])
    y_test_class = pd.cut(y_test, bins=[0, 48, 120, 10000], labels=[0, 1, 2])

    lgb_clf = lgb.LGBMClassifier(
        n_estimators=150,
        max_depth=6,
        learning_rate=0.05,
        num_leaves=31,
        min_child_samples=20,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1,
        verbose=-1,
    )

    lgb_clf.fit(
        X_train,
        y_train_class,
        eval_set=[(X_val, y_val_class)],
        callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)],
    )

    # Avalia√ß√£o
    y_pred_val = lgb_reg.predict(X_val)
    val_mae = mean_absolute_error(y_val, y_pred_val)
    val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))
    val_r2 = r2_score(y_val, y_pred_val)

    y_pred_test = lgb_reg.predict(X_test)
    test_mae = mean_absolute_error(y_test, y_pred_test)
    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
    test_r2 = r2_score(y_test, y_pred_test)

    print(f"\nüìä Resultados:")
    print(f"   Val  ‚Üí MAE: {val_mae:.2f}h | RMSE: {val_rmse:.2f}h | R¬≤: {val_r2:.4f}")
    print(f"   Test ‚Üí MAE: {test_mae:.2f}h | RMSE: {test_rmse:.2f}h | R¬≤: {test_r2:.4f}")

    # Crit√©rio de aceita√ß√£o
    acceptable = test_mae < 30 and test_r2 > 0.40
    status = "‚úÖ ACEIT√ÅVEL" if acceptable else "‚ö†Ô∏è  REVISAR"
    print(f"\n   Status: {status}")

    return {
        "lgb_reg": lgb_reg,
        "lgb_clf": lgb_clf,
        "metrics": {
            "val": {"mae": float(val_mae), "rmse": float(val_rmse), "r2": float(val_r2)},
            "test": {"mae": float(test_mae), "rmse": float(test_rmse), "r2": float(test_r2)},
        },
        "acceptable": acceptable,
    }


def save_light_model(profile, models, features, metrics, output_dir="models"):
    """Salva modelo light treinado."""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    prefix = f"{profile.lower()}_light"

    # Salva modelos
    with open(output_dir / f"{prefix}_lgb_reg.pkl", "wb") as f:
        pickle.dump(models["lgb_reg"], f)

    with open(output_dir / f"{prefix}_lgb_clf.pkl", "wb") as f:
        pickle.dump(models["lgb_clf"], f)

    # Metadata
    metadata = {
        "profile": profile,
        "model_type": "light",
        "is_mock": False,  # MODELO REAL!
        "features": features,
        "target": "tempo_espera_horas",
        "trained_at": datetime.now().isoformat() + "Z",
        "artifacts": {
            "lgb_reg": f"{prefix}_lgb_reg.pkl",
            "lgb_clf": f"{prefix}_lgb_clf.pkl",
        },
        "metrics": metrics,
    }

    with open(output_dir / f"{prefix}_metadata.json", "w") as f:
        json.dump(metadata, f, indent=2)

    print(f"‚úÖ Modelo salvo: models/{prefix}_*")


def main():
    """Fun√ß√£o principal."""
    print("="*60)
    print("TREINO DE MODELOS LIGHT REAIS")
    print("="*60)

    # Carrega dados
    df = load_historical_data()

    if 'tempo_espera_horas' not in df.columns:
        print("‚ùå Coluna 'tempo_espera_horas' n√£o encontrada!")
        return 1

    if 'perfil_modelo' not in df.columns:
        print("‚ö†Ô∏è  Coluna 'perfil_modelo' n√£o encontrada. Usando todos os dados.")
        df['perfil_modelo'] = 'VEGETAL'  # Default

    # Treina para cada perfil
    results = {}

    for profile in ["VEGETAL", "MINERAL", "FERTILIZANTE"]:
        # Filtra dados
        df_profile = df[df['perfil_modelo'] == profile].copy()

        if len(df_profile) < 100:
            print(f"\n‚ö†Ô∏è  Pulando {profile}: apenas {len(df_profile)} registros")
            continue

        # Seleciona features
        features = FEATURES_LIGHT[profile]
        available_features = [f for f in features if f in df_profile.columns]

        if len(available_features) < 10:
            print(f"\n‚ö†Ô∏è  Pulando {profile}: apenas {len(available_features)}/15 features dispon√≠veis")
            continue

        print(f"\n{'='*60}")
        print(f"Perfil: {profile}")
        print(f"Registros: {len(df_profile):,}")
        print(f"Features: {len(available_features)}/15 dispon√≠veis")
        print(f"{'='*60}")

        # Prepara dados
        X = df_profile[available_features]
        y = df_profile["tempo_espera_horas"]

        # Remove NaNs
        mask = ~(X.isna().any(axis=1) | y.isna())
        X = X[mask]
        y = y[mask]

        print(f"Ap√≥s limpeza: {len(X):,} registros")

        if len(X) < 100:
            print(f"‚ö†Ô∏è  Dados insuficientes ap√≥s limpeza")
            continue

        # Split
        X_train, X_temp, y_train, y_temp = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=0.5, random_state=42
        )

        # Treina
        result = train_light_model(
            profile, X_train, y_train, X_val, y_val, X_test, y_test
        )

        # Salva
        save_light_model(
            profile,
            result,
            available_features,
            result["metrics"]
        )

        results[profile] = result

    # Resumo final
    print("\n" + "="*60)
    print("RESUMO DO TREINO")
    print("="*60)

    for profile, result in results.items():
        status = "‚úÖ" if result["acceptable"] else "‚ö†Ô∏è"
        mae = result["metrics"]["test"]["mae"]
        r2 = result["metrics"]["test"]["r2"]
        print(f"{status} {profile:<20} MAE: {mae:.1f}h | R¬≤: {r2:.3f}")

    if not results:
        print("‚ùå Nenhum modelo foi treinado!")
        print("\nPoss√≠veis causas:")
        print("  - Dados insuficientes")
        print("  - Features necess√°rias n√£o dispon√≠veis")
        print("  - Coluna perfil_modelo ausente ou vazia")
        return 1

    print("\n‚úÖ Treino conclu√≠do!")
    print("\nPr√≥ximos passos:")
    print("  1. Testar modelos: python3 test_fallback_system.py")
    print("  2. Executar Streamlit: streamlit run streamlit_app.py")
    print("  3. Validar previs√µes com dados reais")

    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())
```

---

## üìù PASSO 3: Validar Modelos Treinados

Ap√≥s o treino, valide se os modelos foram criados corretamente:

```bash
# Verificar arquivos
ls -lh models/*_light_*

# Executar testes
python3 test_fallback_system.py
```

**Resultados esperados:**
```
‚úÖ VEGETAL light model: OK (15 features)
‚úÖ MINERAL light model: OK (15 features)
‚úÖ FERTILIZANTE light model: OK (15 features)
‚úÖ TODOS OS TESTES PASSARAM!
```

---

## üéØ PASSO 4: Testar no Streamlit

Execute a aplica√ß√£o e teste com dados reais:

```bash
streamlit run streamlit_app.py
```

**O que observar:**
1. Carregue um lineup
2. Veja o badge de qualidade (üü¢üü°üî¥)
3. Se qualidade < 80%, ver√°: üîß **Modelo Simplificado (REAL)**
4. Metadata JSON deve mostrar: `"is_mock": false`

---

## ‚úÖ Crit√©rios de Aceita√ß√£o

Os modelos treinados ser√£o aceitos se:

| M√©trica | Crit√©rio | Import√¢ncia |
|---------|----------|-------------|
| **MAE** | < 30h | ‚≠ê‚≠ê‚≠ê Cr√≠tico |
| **R¬≤** | > 0.40 | ‚≠ê‚≠ê‚≠ê Cr√≠tico |
| **Degrada√ß√£o vs Completo** | < 20% | ‚≠ê‚≠ê Importante |
| **Registros de treino** | >= 100 por perfil | ‚≠ê Desej√°vel |

---

## ‚ö†Ô∏è Troubleshooting

### Problema 1: Poucas Amostras

```
‚ö†Ô∏è Pulando VEGETAL: apenas 50 registros
```

**Solu√ß√£o:**
- Coletar mais dados hist√≥ricos
- Combinar perfis similares
- Reduzir n√∫mero de features (10 ao inv√©s de 15)

### Problema 2: Features Faltando

```
‚ö†Ô∏è Pulando MINERAL: apenas 7/15 features dispon√≠veis
```

**Solu√ß√£o:**
- Treinar com features dispon√≠veis
- Gerar features faltantes (ex: calcular flags)
- Usar modelo completo para esse perfil

### Problema 3: MAE Alto

```
‚ö†Ô∏è REVISAR - MAE: 45.2h | R¬≤: 0.35
```

**Solu√ß√£o:**
- Aumentar dados de treino
- Ajustar hiperpar√¢metros (n_estimators, max_depth)
- Adicionar feature engineering
- Considerar manter modelo MOCK at√© melhorar dados

---

## üì¶ Instru√ß√µes para Agente de IA Local

Se voc√™ est√° usando um agente de IA local para treinar os modelos, forne√ßa estas instru√ß√µes:

```
TAREFA: Treinar modelos light reais para sistema de previs√£o de filas portu√°rias

CONTEXTO:
- Projeto: /home/user/previsao_filas
- Dados: lineups_previstos/lineup_history.parquet (40KB)
- Objetivo: Substituir modelos MOCK por modelos reais com 15 features

PASSOS:
1. Instalar depend√™ncias:
   pip install pandas pyarrow lightgbm scikit-learn numpy

2. Analisar dados dispon√≠veis:
   python3 analise_dados_historicos.py

3. Criar script de treino (se n√£o existir):
   - Copiar c√≥digo do arquivo INSTRUCOES_TREINO_MODELOS_REAIS.md
   - Salvar em pipelines/train_light_models_real.py

4. Executar treino:
   python3 pipelines/train_light_models_real.py

5. Validar resultados:
   python3 test_fallback_system.py

CRIT√âRIOS DE SUCESSO:
- MAE < 30h por perfil
- R¬≤ > 0.40 por perfil
- Modelos salvos em models/*_light_*.pkl
- Metadata com is_mock: false

ENTREG√ÅVEIS:
- 3 modelos treinados (VEGETAL, MINERAL, FERTILIZANTE)
- Metadata JSON atualizado
- Relat√≥rio de m√©tricas (MAE, RMSE, R¬≤)
```

---

## üìä Output Esperado

Ao final do treino bem-sucedido:

```
============================================================
RESUMO DO TREINO
============================================================
‚úÖ VEGETAL              MAE: 22.5h | R¬≤: 0.480
‚úÖ MINERAL              MAE: 28.3h | R¬≤: 0.450
‚úÖ FERTILIZANTE         MAE: 25.7h | R¬≤: 0.420

‚úÖ Treino conclu√≠do!

Pr√≥ximos passos:
  1. Testar modelos: python3 test_fallback_system.py
  2. Executar Streamlit: streamlit run streamlit_app.py
  3. Validar previs√µes com dados reais
```

---

## üéâ Finaliza√ß√£o

Ap√≥s o treino bem-sucedido:

1. ‚úÖ Modelos MOCK ser√£o substitu√≠dos por modelos REAIS
2. ‚úÖ Metadata ter√° `"is_mock": false`
3. ‚úÖ Sistema de fallback continuar√° funcionando automaticamente
4. ‚úÖ Performance ser√° validada com dados hist√≥ricos

**Importante:** Se os resultados n√£o forem aceit√°veis (MAE > 30h ou R¬≤ < 0.40), √© melhor **manter os modelos MOCK** at√© coletar mais dados ou melhorar feature engineering.

---

**Criado em:** 2026-01-28
**Arquivo de dados:** lineups_previstos/lineup_history.parquet
**Tamanho:** 40KB
**Status:** Pronto para treino
