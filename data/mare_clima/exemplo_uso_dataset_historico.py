#!/usr/bin/env python3
"""
Exemplo de Uso dos Datasets HistÃ³ricos Prontos
Datasets:
  1. portos_brasil_historico_portos_hibridos.parquet (Estuarinos)
  2. dados_historicos_complementares_portos_oceanicos_v2.parquet (OceanogrÃ¡ficos)

Este script demonstra como usar os datasets histÃ³ricos prÃ©-processados
que contÃªm dados meteorolÃ³gicos, oceanogrÃ¡ficos e marÃ© astronÃ´mica
para diversos portos brasileiros.
"""

import pandas as pd
import matplotlib.pyplot as plt

def explorar_dataset():
    """Carrega e explora o dataset histÃ³rico"""

    print("=" * 60)
    print("EXPLORANDO DATASET HISTÃ“RICO - PORTOS HÃBRIDOS")
    print("=" * 60)

    # 1. Carregar dataset
    print("\nðŸ“‚ Carregando dataset...")
    try:
        df = pd.read_parquet('portos_brasil_historico_portos_hibridos.parquet')
        print("âœ… Dataset carregado com sucesso!")
    except FileNotFoundError:
        print("âŒ Arquivo nÃ£o encontrado!")
        print("   Certifique-se de que 'portos_brasil_historico_portos_hibridos.parquet'")
        print("   estÃ¡ no diretÃ³rio atual.")
        return

    # 2. InformaÃ§Ãµes gerais
    print("\nðŸ“Š INFORMAÃ‡Ã•ES GERAIS:")
    print(f"   Total de registros: {len(df):,}")
    print(f"   PerÃ­odo: {df['timestamp'].min()} atÃ© {df['timestamp'].max()}")
    print(f"   Colunas: {', '.join(df.columns)}")

    # 3. Registros por porto
    print("\nðŸ¢ REGISTROS POR PORTO:")
    contagem = df['station'].value_counts()
    for porto, count in contagem.items():
        print(f"   {porto}: {count:,} registros")

    # 4. EstatÃ­sticas por variÃ¡vel
    print("\nðŸ“ˆ ESTATÃSTICAS POR VARIÃVEL:")
    print("\nMarÃ© AstronÃ´mica (m):")
    print(df.groupby('station')['mare_astronomica'].describe()[['mean', 'min', 'max', 'std']])

    print("\nVelocidade do Vento (m/s):")
    print(df.groupby('station')['wind_speed'].describe()[['mean', 'min', 'max', 'std']])

    print("\nPressÃ£o AtmosfÃ©rica (mB):")
    print(df.groupby('station')['press'].describe()[['mean', 'min', 'max', 'std']])

    # 5. Verificar dados faltantes
    print("\nâš ï¸  DADOS FALTANTES:")
    missing = df.isnull().sum()
    missing_pct = (missing / len(df)) * 100
    for col, pct in missing_pct.items():
        if pct > 0:
            print(f"   {col}: {pct:.2f}% ({missing[col]:,} registros)")

    if missing.sum() == 0:
        print("   âœ… Nenhum dado faltante!")

    # 6. Exemplo de uso para um porto especÃ­fico
    print("\n" + "=" * 60)
    print("EXEMPLO: ANÃLISE DO PORTO DE PARANAGUÃ")
    print("=" * 60)

    df_paranagua = df[df['station'] == 'Paranagua'].copy()

    print(f"\nðŸ“Š Total de registros: {len(df_paranagua):,}")

    # Calcular features de vento sul
    df_paranagua['vento_sul'] = (
        (df_paranagua['wind_dir'] >= 135) &
        (df_paranagua['wind_dir'] <= 225)
    ).astype(int)

    vento_sul_count = df_paranagua['vento_sul'].sum()
    vento_sul_pct = (vento_sul_count / len(df_paranagua)) * 100

    print(f"ðŸŒ¬ï¸  Vento sul: {vento_sul_count:,} horas ({vento_sul_pct:.1f}% do tempo)")
    print(f"   Velocidade mÃ©dia vento sul: {df_paranagua[df_paranagua['vento_sul']==1]['wind_speed'].mean():.2f} m/s")

    # Amplitude de marÃ©
    amplitude = df_paranagua['mare_astronomica'].max() - df_paranagua['mare_astronomica'].min()
    print(f"\nðŸŒŠ MarÃ© astronÃ´mica:")
    print(f"   MÃ­nima: {df_paranagua['mare_astronomica'].min():.2f} m")
    print(f"   MÃ¡xima: {df_paranagua['mare_astronomica'].max():.2f} m")
    print(f"   Amplitude: {amplitude:.2f} m")

    # Sazonalidade da precipitaÃ§Ã£o
    df_paranagua['mes'] = pd.to_datetime(df_paranagua['timestamp']).dt.month
    precip_mes = df_paranagua.groupby('mes')['precip'].sum()
    mes_mais_chuvoso = precip_mes.idxmax()
    print(f"\nðŸŒ§ï¸  PrecipitaÃ§Ã£o:")
    print(f"   Total acumulado: {df_paranagua['precip'].sum():.1f} mm")
    print(f"   MÃªs mais chuvoso: {mes_mais_chuvoso} ({precip_mes[mes_mais_chuvoso]:.1f} mm)")

    # 7. Dicas de uso
    print("\n" + "=" * 60)
    print("ðŸ’¡ DICAS DE USO PARA MACHINE LEARNING")
    print("=" * 60)

    print("""
    âœ… O que ESTÃ incluÃ­do neste dataset:
       - MarÃ© astronÃ´mica (simplificada com 4 componentes)
       - Dados meteorolÃ³gicos completos (vento, pressÃ£o, precipitaÃ§Ã£o)
       - VazÃ£o fluvial estimada
       - PerÃ­odo: 2020-2024 (5 anos)

    âŒ O que NÃƒO estÃ¡ incluÃ­do (vocÃª precisa obter):
       - NÃ­vel de Ã¡gua OBSERVADO (target para treinar o modelo)
       - Para produÃ§Ã£o: vazÃ£o fluvial real (ANA telemetria)

    ðŸ“ PrÃ³ximos passos:
       1. Obter observaÃ§Ãµes reais do nÃ­vel de Ã¡gua (porto/ANA/Marinha)
       2. Fazer merge com este dataset por timestamp
       3. Treinar modelo de ML
       4. Para maior precisÃ£o: substituir 'mare_astronomica' pelos CSVs
          de alta precisÃ£o gerados pelos scripts Python deste projeto

    ðŸ”— CÃ³digo exemplo:
       df_obs = pd.read_csv('observacoes_paranagua.csv')
       df_completo = pd.merge(df_paranagua, df_obs, on='timestamp')

       features = ['mare_astronomica', 'wind_speed', 'press', 'vazao_fluvial']
       X = df_completo[features]
       y = df_completo['nivel_observado']

       # Treinar modelo...
    """)

def comparar_portos():
    """Compara caracterÃ­sticas entre os trÃªs portos"""

    print("\n" + "=" * 60)
    print("COMPARAÃ‡ÃƒO ENTRE PORTOS")
    print("=" * 60)

    try:
        df = pd.read_parquet('portos_brasil_historico_portos_hibridos.parquet')
    except FileNotFoundError:
        print("âŒ Arquivo nÃ£o encontrado!")
        return

    # ComparaÃ§Ã£o de amplitudes de marÃ©
    print("\nðŸŒŠ AMPLITUDE DE MARÃ‰:")
    for porto in df['station'].unique():
        df_porto = df[df['station'] == porto]
        amplitude = df_porto['mare_astronomica'].max() - df_porto['mare_astronomica'].min()
        print(f"   {porto:15s}: {amplitude:.2f} m")

    # ComparaÃ§Ã£o de vento mÃ©dio
    print("\nðŸŒ¬ï¸  VELOCIDADE MÃ‰DIA DO VENTO:")
    vento_medio = df.groupby('station')['wind_speed'].mean()
    for porto, vel in vento_medio.items():
        print(f"   {porto:15s}: {vel:.2f} m/s")

    # ComparaÃ§Ã£o de rajadas mÃ¡ximas
    print("\nðŸ’¨ RAJADA MÃXIMA REGISTRADA:")
    rajada_max = df.groupby('station')['wind_gust'].max()
    for porto, rajada in rajada_max.items():
        print(f"   {porto:15s}: {rajada:.1f} m/s")

    # ComparaÃ§Ã£o de precipitaÃ§Ã£o total
    print("\nðŸŒ§ï¸  PRECIPITAÃ‡ÃƒO ACUMULADA (2020-2024):")
    precip_total = df.groupby('station')['precip'].sum()
    for porto, precip in precip_total.items():
        print(f"   {porto:15s}: {precip:.0f} mm")

def exemplo_preparacao_ml():
    """Mostra como preparar dados para ML"""

    print("\n" + "=" * 60)
    print("EXEMPLO: PREPARAÃ‡ÃƒO PARA MACHINE LEARNING")
    print("=" * 60)

    try:
        df = pd.read_parquet('portos_brasil_historico_portos_hibridos.parquet')
    except FileNotFoundError:
        print("âŒ Arquivo nÃ£o encontrado!")
        return

    # Filtrar porto
    df_porto = df[df['station'] == 'Paranagua'].copy()

    print(f"\n1ï¸âƒ£  Filtrado porto: ParanaguÃ¡ ({len(df_porto):,} registros)")

    # Criar features adicionais
    df_porto['hora'] = pd.to_datetime(df_porto['timestamp']).dt.hour
    df_porto['mes'] = pd.to_datetime(df_porto['timestamp']).dt.month
    df_porto['dia_semana'] = pd.to_datetime(df_porto['timestamp']).dt.dayofweek

    # Vento sul
    df_porto['vento_sul'] = (
        (df_porto['wind_dir'] >= 135) &
        (df_porto['wind_dir'] <= 225)
    ).astype(int)
    df_porto['vento_sul_vel'] = df_porto['wind_speed'] * df_porto['vento_sul']

    # Rolling features
    df_porto['wind_speed_max_24h'] = df_porto['wind_speed'].rolling(window=24, min_periods=1).max()
    df_porto['precip_acum_24h'] = df_porto['precip'].rolling(window=24, min_periods=1).sum()

    print("2ï¸âƒ£  Features criadas:")
    print("   - Temporais: hora, mes, dia_semana")
    print("   - Vento sul: vento_sul, vento_sul_vel")
    print("   - Rolling: wind_speed_max_24h, precip_acum_24h")

    # Lista de features para ML
    features_ml = [
        'mare_astronomica',
        'wind_speed',
        'wind_dir',
        'wind_gust',
        'press',
        'precip',
        'vazao_fluvial',
        'hora',
        'mes',
        'vento_sul',
        'vento_sul_vel',
        'wind_speed_max_24h',
        'precip_acum_24h'
    ]

    print(f"\n3ï¸âƒ£  Total de features preparadas: {len(features_ml)}")
    print(f"   Features: {', '.join(features_ml)}")

    # Verificar correlaÃ§Ãµes
    print("\n4ï¸âƒ£  CorrelaÃ§Ãµes com marÃ© astronÃ´mica:")
    correlacoes = df_porto[features_ml].corr()['mare_astronomica'].sort_values(ascending=False)
    print(correlacoes.head(10))

    print("\nâš ï¸  PRÃ“XIMO PASSO CRÃTICO:")
    print("   VocÃª precisa obter observaÃ§Ãµes REAIS do nÃ­vel de Ã¡gua!")
    print("   Fontes: Porto de ParanaguÃ¡, Marinha do Brasil, ou ANA")
    print("   Arquivo exemplo: observacoes_paranagua_2020_2024.csv")
    print("\n   Depois:")
    print("   df_obs = pd.read_csv('observacoes_paranagua_2020_2024.csv')")
    print("   df_final = pd.merge(df_porto, df_obs, on='timestamp', how='inner')")
    print("   X = df_final[features_ml]")
    print("   y = df_final['nivel_observado']")

def explorar_dataset_oceanografico():
    """Explora o dataset oceanogrÃ¡fico complementar"""

    print("\n" + "=" * 60)
    print("EXPLORANDO DATASET OCEANOGRÃFICO E METEOROLÃ“GICO")
    print("=" * 60)

    try:
        df = pd.read_parquet('dados_historicos_complementares_portos_oceanicos_v2.parquet')
        print("âœ… Dataset oceanogrÃ¡fico carregado com sucesso!")
    except FileNotFoundError:
        print("âŒ Arquivo nÃ£o encontrado!")
        print("   'dados_historicos_complementares_portos_oceanicos_v2.parquet'")
        print("   nÃ£o estÃ¡ no diretÃ³rio atual.")
        return

    # InformaÃ§Ãµes gerais
    print("\nðŸ“Š INFORMAÃ‡Ã•ES GERAIS:")
    print(f"   Total de registros: {len(df):,}")
    print(f"   PerÃ­odo: {df['timestamp'].min()} atÃ© {df['timestamp'].max()}")
    print(f"   Portos: {', '.join(df['station'].unique())}")

    # Portos oceÃ¢nicos vs fluviais
    portos_oceanicos = ['Santos', 'Paranagua', 'Itaqui', 'RioGrande',
                        'SaoFranciscoDoSul', 'Vitoria', 'Suape', 'Itajai',
                        'Recife', 'Pecem', 'Salvador']
    portos_fluviais = ['Santarem', 'Barcarena']

    df_oceanicos = df[df['station'].isin(portos_oceanicos)]
    df_fluviais = df[df['station'].isin(portos_fluviais)]

    print(f"\n   Portos oceÃ¢nicos: {len(portos_oceanicos)}")
    print(f"   Portos fluviais: {len(portos_fluviais)}")

    # EstatÃ­sticas de ondas (apenas oceÃ¢nicos)
    print("\nðŸŒŠ ONDAS (Portos OceÃ¢nicos):")
    wave_stats = df_oceanicos.groupby('station')['wave_height'].describe()[['mean', 'max', 'std']]
    print(wave_stats)

    # Onda mÃ¡xima registrada
    idx_max_wave = df_oceanicos['wave_height'].idxmax()
    max_wave_row = df_oceanicos.loc[idx_max_wave]
    print(f"\n   ðŸŒŠ Maior onda registrada:")
    print(f"      {max_wave_row['wave_height']:.2f} m em {max_wave_row['station']}")
    print(f"      Data: {max_wave_row['timestamp']}")

    # Eventos de frente fria
    df_frentes = df[df['frente_fria'] == True]
    print(f"\nâ„ï¸  FRENTES FRIAS:")
    print(f"   Total de eventos: {len(df_frentes):,}")
    print(f"   Por porto:")
    frentes_por_porto = df_frentes['station'].value_counts()
    for porto, count in frentes_por_porto.items():
        pct = (count / len(df[df['station'] == porto])) * 100
        print(f"      {porto:20s}: {count:5d} eventos ({pct:.1f}% do tempo)")

    # Anomalia de pressÃ£o
    print(f"\nðŸŒ¡ï¸  ANOMALIA DE PRESSÃƒO:")
    anomalia_stats = df.groupby('station')['pressao_anomalia'].describe()[['mean', 'min', 'max']]
    print(anomalia_stats)

    # Exemplo Santos - Ressacas
    print("\n" + "=" * 60)
    print("EXEMPLO: SANTOS - ANÃLISE DE RESSACAS")
    print("=" * 60)

    df_santos = df[df['station'] == 'Santos'].copy()

    # Definir ressacas
    df_santos['ressaca'] = df_santos['wave_height'] > 2.5
    df_santos['ressaca_forte'] = df_santos['wave_height'] > 3.5

    n_ressacas = df_santos['ressaca'].sum()
    n_ressacas_fortes = df_santos['ressaca_forte'].sum()

    print(f"\nðŸŒŠ Eventos de Ressaca em Santos:")
    print(f"   Ressacas (>2.5m): {n_ressacas:,} horas ({n_ressacas/len(df_santos)*100:.1f}% do tempo)")
    print(f"   Ressacas fortes (>3.5m): {n_ressacas_fortes:,} horas ({n_ressacas_fortes/len(df_santos)*100:.1f}% do tempo)")

    # CorrelaÃ§Ã£o ressaca + vento sul
    df_santos['vento_sul'] = (
        (df_santos['wind_direction_10m'] >= 135) &
        (df_santos['wind_direction_10m'] <= 225)
    ).astype(int)

    ressacas_vento_sul = df_santos[df_santos['ressaca'] & df_santos['vento_sul']].shape[0]
    print(f"\nðŸ’¨ Ressacas com Vento Sul: {ressacas_vento_sul:,} ({ressacas_vento_sul/n_ressacas*100:.1f}% das ressacas)")

    # Sazonalidade das ressacas
    df_santos['mes'] = pd.to_datetime(df_santos['timestamp']).dt.month
    ressacas_por_mes = df_santos[df_santos['ressaca']].groupby('mes').size()
    mes_mais_ressacas = ressacas_por_mes.idxmax()
    print(f"\nðŸ“… Sazonalidade:")
    print(f"   MÃªs com mais ressacas: {mes_mais_ressacas} ({ressacas_por_mes[mes_mais_ressacas]} eventos)")

    print("\nðŸ’¡ DICA: Combine este dataset com as previsÃµes astronÃ´micas")
    print("   deste projeto para separar efeitos meteorolÃ³gicos da marÃ©!")

def comparar_datasets():
    """Compara os dois datasets disponÃ­veis"""

    print("\n" + "=" * 60)
    print("COMPARAÃ‡ÃƒO ENTRE OS DOIS DATASETS")
    print("=" * 60)

    try:
        df1 = pd.read_parquet('portos_brasil_historico_portos_hibridos.parquet')
        df2 = pd.read_parquet('dados_historicos_complementares_portos_oceanicos_v2.parquet')
    except FileNotFoundError as e:
        print(f"âŒ Arquivo nÃ£o encontrado: {e}")
        return

    print("\nðŸ“Š DATASET 1 - Portos HÃ­bridos (Estuarinos):")
    print(f"   Portos: {', '.join(df1['station'].unique())}")
    print(f"   PerÃ­odo: {df1['timestamp'].min().date()} a {df1['timestamp'].max().date()}")
    print(f"   Registros: {len(df1):,}")
    print(f"   VariÃ¡veis: {len(df1.columns)}")
    print(f"   Principais: mare_astronomica, wind_speed, press, vazao_fluvial")

    print("\nðŸ“Š DATASET 2 - OceanogrÃ¡ficos:")
    print(f"   Portos: {', '.join(df2['station'].unique())}")
    print(f"   PerÃ­odo: {df2['timestamp'].min().date()} a {df2['timestamp'].max().date()}")
    print(f"   Registros: {len(df2):,}")
    print(f"   VariÃ¡veis: {len(df2.columns)}")
    print(f"   Principais: wave_height, sea_level_height_msl, frente_fria, pressao_anomalia")

    # Portos em comum
    portos_comum = set(df1['station'].unique()) & set(df2['station'].unique())
    print(f"\nðŸ”„ Portos em AMBOS os datasets: {', '.join(portos_comum)}")

    if portos_comum:
        print("\n   ðŸ’¡ Para esses portos vocÃª pode:")
        print("      - Comparar INMET vs ERA5")
        print("      - Validar modelos com diferentes fontes")
        print("      - Combinar vazÃ£o (Dataset1) + ondas (Dataset2)")

if __name__ == '__main__':
    # Executar todas as anÃ¡lises
    print("=" * 60)
    print("ANÃLISE DOS DATASETS HISTÃ“RICOS DE MARÃ‰S")
    print("=" * 60)

    # Dataset 1 - Estuarinos
    print("\n\n[1/5] DATASET 1 - PORTOS HÃBRIDOS")
    explorar_dataset()

    print("\n\n[2/5] DATASET 1 - COMPARAÃ‡ÃƒO ENTRE PORTOS")
    comparar_portos()

    print("\n\n[3/5] DATASET 1 - PREPARAÃ‡ÃƒO PARA ML")
    exemplo_preparacao_ml()

    # Dataset 2 - OceanogrÃ¡ficos
    print("\n\n[4/5] DATASET 2 - OCEANOGRÃFICOS")
    explorar_dataset_oceanografico()

    # ComparaÃ§Ã£o entre datasets
    print("\n\n[5/5] COMPARAÃ‡ÃƒO ENTRE DATASETS")
    comparar_datasets()

    print("\n" + "=" * 60)
    print("âœ… AnÃ¡lise completa concluÃ­da!")
    print("=" * 60)
    print("\nðŸ’¡ PrÃ³ximos passos:")
    print("   1. Obter observaÃ§Ãµes reais do nÃ­vel de Ã¡gua (target)")
    print("   2. Escolher o dataset mais adequado ao seu caso")
    print("   3. Feature engineering adicional conforme necessidade")
    print("   4. Treinar modelo de ML")
    print("   5. Validar com dados independentes")
