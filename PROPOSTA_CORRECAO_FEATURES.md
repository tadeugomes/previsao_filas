# Proposta de Corre√ß√£o: Inconsist√™ncias entre Colunas e Features do Modelo

**Data:** 2026-01-27
**Problema:** Modelos b√°sicos esperam 38-54 features, mas lineups fornecem apenas 5 colunas
**Objetivo:** Propor solu√ß√µes pr√°ticas e implement√°veis para melhorar a qualidade das previs√µes

---

## 1. An√°lise do Problema

### 1.1 Situa√ß√£o Atual

**Dados dispon√≠veis no lineup (entrada do usu√°rio):**
```
- Navio (nome do navio)
- Mercadoria (tipo de carga)
- Chegada (data/hora prevista de chegada)
- Berco (terminal de destino)
- DWT (opcional - tonelagem do navio)
```

**Features esperadas pelos modelos:**
- **VEGETAL:** 54 features
- **MINERAL:** 38 features
- **FERTILIZANTE:** 38 features
- **PONTA_DA_MADEIRA (Premium):** 10 features

**Gap atual:** 5 colunas fornecidas ‚Üí 38-54 features necess√°rias = **33-49 features faltantes (87-91%)**

### 1.2 Classifica√ß√£o das Features por Fonte de Dados

Analisando as 54 features do modelo VEGETAL:

#### **Categoria A: Derivadas do Lineup (5 features - 9%)**
‚úÖ Dispon√≠veis diretamente do lineup:
```
1. nome_porto ‚Üí inferido do arquivo ou sele√ß√£o do usu√°rio
2. nome_terminal ‚Üí coluna "Berco"
3. natureza_carga ‚Üí coluna "Mercadoria"
4. movimentacao_total_toneladas ‚Üí coluna "DWT"
5. mes, dia_semana, dia_do_ano ‚Üí derivados de "Chegada"
```

#### **Categoria B: Hardcoded/Defaults Razo√°veis (7 features - 13%)**
‚ö†Ô∏è Valores fixos que fazem sentido para o contexto brasileiro:
```
6. tipo_navegacao ‚Üí "Longo Curso" (99% dos casos)
7. tipo_carga ‚Üí "Granel" (contexto de commodities)
8. cdmercadoria ‚Üí "0000" (c√≥digo desconhecido)
9. stsh4 ‚Üí "0000" (c√≥digo desconhecido)
10. restricao_vento ‚Üí 0 (sem restri√ß√£o, conservador)
11. restricao_chuva ‚Üí 0 (sem restri√ß√£o, conservador)
12. flag_celulose, flag_algodao, flag_soja, flag_milho ‚Üí derivados de "Mercadoria"
```

#### **Categoria C: Contexto Temporal (1 feature - 2%)**
‚úÖ Podem ser inferidos de forma confi√°vel:
```
13. periodo_safra ‚Üí baseado no m√™s (mar√ßo-junho)
```

#### **Categoria D: APIs Externas - Clima (8-16 features - 15-30%)**
üîß Dispon√≠veis via APIs (Open-Meteo, INMET, BigQuery):
```
14. temp_media_dia
15. precipitacao_dia
16. vento_rajada_max_dia
17. vento_velocidade_media (somente VEGETAL)
18. umidade_media_dia
19. amplitude_termica
20. chuva_acumulada_ultimos_3dias
21. wave_height_max (VEGETAL)
22. wave_height_media (VEGETAL)
23. frente_fria (VEGETAL)
24. pressao_anomalia (VEGETAL)
25. ressaca (VEGETAL)
```

**Status atual:** Implementado parcialmente
- ‚úÖ Open-Meteo API dispon√≠vel
- ‚úÖ BigQuery INMET dispon√≠vel (requer credenciais)
- ‚ö†Ô∏è Oceano/mar√©: parcialmente implementado

#### **Categoria E: APIs Externas - AIS (5 features - 9%)**
üîß Dispon√≠veis via APIs AIS (MarineTraffic, VesselFinder):
```
26. ais_navios_no_raio
27. ais_fila_ao_largo
28. ais_velocidade_media_kn
29. ais_eta_media_horas
30. ais_dist_media_km
```

**Status atual:** Estrutura existe, mas dados AIS n√£o s√£o carregados automaticamente

#### **Categoria F: APIs Externas - Mar√© (6 features - 11%)**
üîß Dispon√≠veis via dados de mar√© astron√¥mica:
```
31. mare_astronomica
32. mare_subindo
33. mare_horas_ate_extremo
34. tem_mare_astronomica
```

**Status atual:** Implementado, dados hist√≥ricos dispon√≠veis em `data/mare_clima/`

#### **Categoria G: APIs Externas - Economia (6 features - 11%)**
üîß Dispon√≠veis via APIs (IBGE PAM, IPEA):
```
35. producao_soja
36. producao_milho
37. producao_algodao
38. preco_soja_mensal
39. preco_milho_mensal
40. preco_algodao_mensal
```

**Status atual:** Implementado via BigQuery (requer credenciais)

#### **Categoria H: Calculadas - Fila (3 features - 6%)**
‚ùå **PROBLEMA CR√çTICO** - Calculadas incorretamente:
```
41. navios_no_fundeio_na_chegada ‚Üí ERRADO: usa df.index
42. navios_na_fila_7d ‚Üí ERRADO: baseado em janela simples
43. tempo_espera_ma5 ‚Üí FIXO: sempre 0.0
```

#### **Categoria I: Calculadas - Hist√≥rico (1 feature - 2%)**
‚ùå **PROBLEMA** - Valor fixo:
```
44. porto_tempo_medio_historico ‚Üí FIXO: sempre 0.0
```

#### **Categoria J: Calculadas - Press√£o de Mercado (2 features - 4%)**
‚ùå **PROBLEMA** - Valores fixos:
```
45. indice_pressao_soja ‚Üí FIXO: sempre 0.0
46. indice_pressao_milho ‚Üí FIXO: sempre 0.0
```

### 1.3 Resumo do Diagn√≥stico

| Categoria | Features | % | Status | Impacto no Modelo |
|-----------|----------|---|--------|-------------------|
| **A. Lineup** | 5 | 9% | ‚úÖ OK | **ALTO** - dados reais |
| **B. Defaults** | 7 | 13% | ‚ö†Ô∏è Razo√°vel | **M√âDIO** - valores conservadores |
| **C. Temporal** | 1 | 2% | ‚úÖ OK | **M√âDIO** |
| **D. Clima** | 8-16 | 15-30% | üîß Parcial | **ALTO** - clima afeta opera√ß√µes |
| **E. AIS** | 5 | 9% | ‚ùå N√£o usado | **ALTO** - indica fila real |
| **F. Mar√©** | 4-6 | 7-11% | üîß Parcial | **M√âDIO** - afeta alguns portos |
| **G. Economia** | 6 | 11% | üîß Parcial | **BAIXO** - contexto macro |
| **H. Fila** | 3 | 6% | ‚ùå **ERRADO** | **CR√çTICO** - fila √© preditor principal |
| **I. Hist√≥rico** | 1 | 2% | ‚ùå Fixo 0 | **ALTO** - baseline importante |
| **J. Press√£o** | 2 | 4% | ‚ùå Fixo 0 | **BAIXO** - refinamento |

**Conclus√£o:**
- ‚úÖ **21% das features est√£o OK** (12/54)
- ‚ö†Ô∏è **44% poderiam ser obtidas via APIs** (24/54)
- ‚ùå **11% est√£o CRITICAMENTE ERRADAS** (6/54 - fila e hist√≥rico)
- ‚ö†Ô∏è **24% t√™m defaults question√°veis** (restante)

---

## 2. Propostas de Corre√ß√£o

### 2.1 Abordagem Recomendada: **H√≠brida com Valida√ß√£o**

N√£o exigir re-treino imediato dos modelos, mas:
1. **Corrigir c√°lculos cr√≠ticos** (fila, hist√≥rico)
2. **Melhorar obten√ß√£o de dados de APIs** (clima, AIS, mar√©)
3. **Adicionar sistema de valida√ß√£o e confian√ßa**
4. **Preparar para modelos simplificados no futuro**

### 2.2 Solu√ß√£o Detalhada por Categoria

#### **PRIORIDADE 1: Corrigir Features Cr√≠ticas (Categoria H e I)**

**Feature: `navios_no_fundeio_na_chegada`**

‚ùå **C√≥digo atual (streamlit_app.py:1019):**
```python
df["navios_no_fundeio_na_chegada"] = df.index.astype(float)
```

‚úÖ **C√≥digo corrigido:**
```python
def calcular_fila_simulada(df_lineup):
    """
    Calcula quantos navios estar√£o no fundeio quando cada navio chegar.
    Usa simula√ß√£o simplificada baseada em taxa m√©dia de atraca√ß√£o.
    """
    df = df_lineup.copy()
    df = df.sort_values("data_chegada_dt").reset_index(drop=True)

    # Taxa m√©dia de atraca√ß√£o por hora (ajustar por porto/perfil)
    TAXA_ATRACACAO_MEDIA_HORAS = {
        "VEGETAL": 72,      # 3 dias em m√©dia
        "MINERAL": 48,      # 2 dias em m√©dia
        "FERTILIZANTE": 96  # 4 dias em m√©dia
    }

    fila = np.zeros(len(df))

    for i in range(len(df)):
        chegada_i = df.loc[i, "data_chegada_dt"]
        perfil_i = df.loc[i, "perfil_modelo"] if "perfil_modelo" in df.columns else "VEGETAL"
        taxa_media = TAXA_ATRACACAO_MEDIA_HORAS.get(perfil_i, 72)

        # Conta quantos navios anteriores ainda estar√£o no fundeio
        navios_no_fundeio = 0
        for j in range(i):
            chegada_j = df.loc[j, "data_chegada_dt"]
            tempo_desde_chegada = (chegada_i - chegada_j).total_seconds() / 3600  # horas

            # Se o navio j chegou h√° menos tempo que a taxa m√©dia, ainda est√° no fundeio
            if tempo_desde_chegada < taxa_media:
                navios_no_fundeio += 1

        fila[i] = navios_no_fundeio

    return fila
```

**Feature: `porto_tempo_medio_historico`**

‚ùå **C√≥digo atual:** sempre 0.0

‚úÖ **C√≥digo corrigido:**
```python
def carregar_tempo_medio_historico(porto_nome):
    """
    Carrega tempo m√©dio hist√≥rico de espera para o porto.
    Usa lineup_history.parquet ou valores default por porto.
    """
    # Valores default baseados em dados reais (horas)
    TEMPO_MEDIO_DEFAULT = {
        "SANTOS": 48,
        "PARANAGUA": 72,
        "ITAQUI": 36,
        "PONTA_DA_MADEIRA": 24,
        "VILA_DO_CONDE": 60,
        "BARCARENA": 60,
        "RIO_GRANDE": 48,
        "SUAPE": 72,
        "PECEM": 48,
        "SALVADOR": 60,
        "VITORIA": 48,
        "SAO_FRANCISCO_DO_SUL": 60,
    }

    porto_norm = normalizar_texto(porto_nome)

    # Tenta carregar do hist√≥rico
    try:
        df_hist = load_lineup_history()
        if not df_hist.empty and "tempo_espera_horas" in df_hist.columns:
            df_porto = df_hist[df_hist["porto"].apply(normalizar_texto) == porto_norm]
            if len(df_porto) >= 10:  # M√≠nimo 10 registros hist√≥ricos
                tempo_medio = df_porto["tempo_espera_horas"].median()
                return float(tempo_medio)
    except Exception:
        pass

    # Fallback para valores default
    for key, value in TEMPO_MEDIO_DEFAULT.items():
        if normalizar_texto(key) == porto_norm:
            return float(value)

    return 48.0  # Default gen√©rico: 2 dias
```

**Feature: `tempo_espera_ma5`**

‚ùå **C√≥digo atual:** sempre 0.0

‚úÖ **C√≥digo corrigido:**
```python
def calcular_tempo_espera_ma5(df_lineup):
    """
    Calcula m√©dia m√≥vel de 5 per√≠odos do tempo de espera.
    Como n√£o temos hist√≥rico no lineup, usa tempo m√©dio do porto.
    """
    df = df_lineup.copy()

    if "porto_tempo_medio_historico" in df.columns:
        # Usa o tempo m√©dio hist√≥rico como proxy
        df["tempo_espera_ma5"] = df["porto_tempo_medio_historico"]
    else:
        df["tempo_espera_ma5"] = 48.0  # Default: 2 dias

    return df["tempo_espera_ma5"].values
```

#### **PRIORIDADE 2: Melhorar Obten√ß√£o de Dados de APIs**

**Feature: Dados de Clima (Categoria D)**

‚úÖ **J√° implementado parcialmente** via Open-Meteo e BigQuery INMET

üîß **Melhorias necess√°rias:**
```python
def obter_dados_clima_completos(porto_nome, data_chegada, live_data):
    """
    Obt√©m dados de clima de m√∫ltiplas fontes com fallback.
    """
    # Prioridade 1: BigQuery INMET (mais preciso)
    if BIGQUERY_AVAILABLE:
        try:
            clima_inmet = fetch_inmet_latest(
                station_id=get_station_id(porto_nome),
                port_name=porto_nome
            )
            if clima_inmet and clima_inmet.get("temp_media_dia"):
                return clima_inmet
        except Exception as e:
            st.warning(f"BigQuery INMET indispon√≠vel: {e}")

    # Prioridade 2: Open-Meteo (fallback)
    if WEATHER_API_AVAILABLE:
        try:
            from weather_api import get_weather_forecast
            lat, lon = get_porto_coords(porto_nome)
            clima_openmeteo = get_weather_forecast(lat, lon, data_chegada)
            return clima_openmeteo
        except Exception as e:
            st.warning(f"Open-Meteo indispon√≠vel: {e}")

    # Prioridade 3: Valores conservadores (fallback final)
    st.warning(f"Usando valores clim√°ticos conservadores para {porto_nome}")
    return {
        "temp_media_dia": 25.0,
        "precipitacao_dia": 0.0,
        "vento_rajada_max_dia": 5.0,
        "umidade_media_dia": 70.0,
        "amplitude_termica": 10.0,
    }
```

**Feature: Dados AIS (Categoria E)**

‚ùå **N√£o implementado** - estrutura existe mas n√£o √© usada

‚úÖ **Implementa√ß√£o recomendada:**
```python
def carregar_ais_features_por_data(porto_nome, data_chegada):
    """
    Carrega features AIS do arquivo pre-processado.
    """
    # Verifica se existe arquivo AIS para o porto
    porto_norm = normalizar_texto(porto_nome)
    ais_file = AIS_FEATURES_DIR / f"{porto_norm}_ais_features.parquet"

    if not ais_file.exists():
        # Retorna valores default (n√£o h√° dados AIS)
        return pd.DataFrame({
            "ais_navios_no_raio": [0.0],
            "ais_fila_ao_largo": [0.0],
            "ais_velocidade_media_kn": [0.0],
            "ais_eta_media_horas": [0.0],
            "ais_dist_media_km": [0.0],
        })

    try:
        df_ais = pd.read_parquet(ais_file)
        df_ais["date"] = pd.to_datetime(df_ais["date"]).dt.date

        # Busca dados para a data espec√≠fica ou usa o mais recente
        data_alvo = pd.to_datetime(data_chegada).date()
        df_data = df_ais[df_ais["date"] == data_alvo]

        if df_data.empty:
            # Usa dados mais recentes dispon√≠veis
            df_data = df_ais.sort_values("date", ascending=False).head(1)
            st.info(f"Usando dados AIS de {df_data['date'].iloc[0]} (mais recentes dispon√≠veis)")

        return df_data
    except Exception as e:
        st.warning(f"Erro ao carregar dados AIS: {e}")
        return pd.DataFrame({
            "ais_navios_no_raio": [0.0],
            "ais_fila_ao_largo": [0.0],
            "ais_velocidade_media_kn": [0.0],
            "ais_eta_media_horas": [0.0],
            "ais_dist_media_km": [0.0],
        })
```

**Feature: Dados de Mar√© (Categoria F)**

‚úÖ **J√° implementado** via `adicionar_features_mare_lineup()`

üîß **Verificar funcionamento correto** - parece OK no c√≥digo atual (streamlit_app.py:1000)

#### **PRIORIDADE 3: Sistema de Valida√ß√£o e Confian√ßa**

**Classe para rastrear qualidade dos dados:**

```python
from dataclasses import dataclass
from typing import Dict, List
from enum import Enum

class FeatureQuality(Enum):
    """Qualidade da feature preenchida"""
    REAL = "real"              # Dado real do lineup
    API_OK = "api_ok"          # Obtido de API com sucesso
    API_FALLBACK = "api_fallback"  # API falhou, usando fallback
    CALCULATED = "calculated"  # Calculado corretamente
    DEFAULT = "default"        # Valor default razo√°vel
    CRITICAL_DEFAULT = "critical_default"  # Valor default em feature cr√≠tica

@dataclass
class FeatureReport:
    """Relat√≥rio de qualidade das features para uma previs√£o"""
    total_features: int
    quality_breakdown: Dict[FeatureQuality, int]
    critical_issues: List[str]
    warnings: List[str]
    confidence_score: float  # 0-100

    def to_dict(self):
        return {
            "total_features": self.total_features,
            "quality": {k.value: v for k, v in self.quality_breakdown.items()},
            "critical_issues": self.critical_issues,
            "warnings": self.warnings,
            "confidence": self.confidence_score
        }

def avaliar_qualidade_features(df_features, metadata, api_status):
    """
    Avalia a qualidade das features preenchidas.

    Args:
        df_features: DataFrame com features preenchidas
        metadata: Metadados do modelo (lista de features esperadas)
        api_status: Dict com status de cada API (clima, ais, mare, etc.)

    Returns:
        FeatureReport com an√°lise de qualidade
    """
    features = metadata["features"]
    quality_breakdown = {q: 0 for q in FeatureQuality}
    critical_issues = []
    warnings = []

    # Features do lineup (Categoria A)
    lineup_features = ["nome_porto", "nome_terminal", "natureza_carga",
                       "movimentacao_total_toneladas", "mes", "dia_semana", "dia_do_ano"]
    for feat in lineup_features:
        if feat in features:
            quality_breakdown[FeatureQuality.REAL] += 1

    # Features de clima (Categoria D)
    clima_features = ["temp_media_dia", "precipitacao_dia", "vento_rajada_max_dia",
                      "umidade_media_dia", "amplitude_termica", "chuva_acumulada_ultimos_3dias"]
    if api_status.get("clima_ok", False):
        quality_breakdown[FeatureQuality.API_OK] += len([f for f in clima_features if f in features])
    else:
        quality_breakdown[FeatureQuality.API_FALLBACK] += len([f for f in clima_features if f in features])
        warnings.append("Dados de clima n√£o dispon√≠veis - usando valores conservadores")

    # Features AIS (Categoria E)
    ais_features = ["ais_navios_no_raio", "ais_fila_ao_largo", "ais_velocidade_media_kn",
                    "ais_eta_media_horas", "ais_dist_media_km"]
    if api_status.get("ais_ok", False):
        quality_breakdown[FeatureQuality.API_OK] += len([f for f in ais_features if f in features])
    else:
        quality_breakdown[FeatureQuality.CRITICAL_DEFAULT] += len([f for f in ais_features if f in features])
        critical_issues.append("‚ö†Ô∏è Dados AIS n√£o dispon√≠veis - fila real desconhecida")

    # Features de fila calculadas (Categoria H)
    fila_features = ["navios_no_fundeio_na_chegada", "navios_na_fila_7d"]
    quality_breakdown[FeatureQuality.CALCULATED] += len([f for f in fila_features if f in features])

    # Features hist√≥ricas (Categoria I)
    if "porto_tempo_medio_historico" in features:
        if api_status.get("historico_ok", False):
            quality_breakdown[FeatureQuality.CALCULATED] += 1
        else:
            quality_breakdown[FeatureQuality.DEFAULT] += 1
            warnings.append("Tempo m√©dio hist√≥rico baseado em valores t√≠picos do porto")

    # Features econ√¥micas (Categoria G)
    econ_features = ["producao_soja", "producao_milho", "preco_soja_mensal", "preco_milho_mensal"]
    if api_status.get("economia_ok", False):
        quality_breakdown[FeatureQuality.API_OK] += len([f for f in econ_features if f in features])
    else:
        quality_breakdown[FeatureQuality.DEFAULT] += len([f for f in econ_features if f in features])
        warnings.append("Dados econ√¥micos n√£o dispon√≠veis - usando valores default")

    # Defaults (resto)
    defaults_count = len(features) - sum(quality_breakdown.values())
    quality_breakdown[FeatureQuality.DEFAULT] += defaults_count

    # Calcula score de confian√ßa
    total = len(features)
    score = (
        quality_breakdown[FeatureQuality.REAL] * 1.0 +
        quality_breakdown[FeatureQuality.API_OK] * 0.9 +
        quality_breakdown[FeatureQuality.CALCULATED] * 0.8 +
        quality_breakdown[FeatureQuality.DEFAULT] * 0.5 +
        quality_breakdown[FeatureQuality.API_FALLBACK] * 0.4 +
        quality_breakdown[FeatureQuality.CRITICAL_DEFAULT] * 0.2
    ) / total * 100

    return FeatureReport(
        total_features=total,
        quality_breakdown=quality_breakdown,
        critical_issues=critical_issues,
        warnings=warnings,
        confidence_score=round(score, 1)
    )
```

**Integra√ß√£o no fluxo de previs√£o:**

```python
def predict_lineup_basico_v2(df_lineup, live_data, porto_nome):
    """
    Vers√£o melhorada com valida√ß√£o e rastreamento de qualidade.
    """
    df = df_lineup.copy()
    df["perfil_modelo"] = df.apply(get_profile_from_row, axis=1)

    # Rastreia status das APIs
    api_status = {
        "clima_ok": live_data.get("clima") is not None,
        "ais_ok": live_data.get("ais_df") is not None and not live_data["ais_df"].empty,
        "economia_ok": live_data.get("pam") is not None and live_data.get("precos") is not None,
        "historico_ok": False,  # Ser√° atualizado por carregar_tempo_medio_historico()
    }

    dfs = []
    feature_reports = []

    for profile, sub in df.groupby("perfil_modelo", dropna=False):
        models = load_models_for_profile(profile)
        if not models:
            sub["tempo_espera_previsto_horas"] = np.nan
            sub["tempo_espera_previsto_dias"] = np.nan
            sub["classe_espera_prevista"] = "Indisponivel"
            sub["risco_previsto"] = "Indisponivel"
            sub["probabilidade_prevista"] = np.nan
            sub["confianca_previsao"] = 0.0
            dfs.append(sub)
            continue

        # Constr√≥i features com rastreamento
        features_data = build_features_from_lineup(sub, models["metadata"], live_data, porto_nome)

        # Avalia qualidade das features
        report = avaliar_qualidade_features(features_data, models["metadata"], api_status)

        # Faz previs√£o
        preds_horas = None
        if models.get("model_ensemble") is not None:
            ensemble = models["model_ensemble"]
            try:
                if hasattr(ensemble, "xgb_model"):
                    X_xgb = build_xgb_features_from_lgb(features_data, ensemble.xgb_model)
                    preds = ensemble.predict(X_xgb, X_lgb=features_data)
                else:
                    preds = ensemble.predict(features_data)
                preds_horas = pd.Series(preds).apply(lambda v: float(max(0.0, v)))
            except Exception:
                preds_horas = None

        if preds_horas is None:
            preds_horas = pd.Series(models["model_reg"].predict(features_data)).apply(
                lambda v: float(max(0.0, np.expm1(v)))
            )

        sub["tempo_espera_previsto_horas"] = preds_horas.round(2).to_numpy()
        sub["tempo_espera_previsto_dias"] = (sub["tempo_espera_previsto_horas"] / 24.0).round(2)
        sub["confianca_previsao"] = report.confidence_score

        # Adiciona avisos ao DataFrame
        if report.critical_issues:
            sub["avisos_criticos"] = ", ".join(report.critical_issues)
        if report.warnings:
            sub["avisos"] = ", ".join(report.warnings)

        class_pred = models["model_clf"].predict(features_data)
        class_map = {0: "R√°pido", 1: "M√©dio", 2: "Longo"}
        risco_map = {0: "Baixo", 1: "M√©dio", 2: "Alto"}
        sub["classe_espera_prevista"] = (
            pd.Series(class_pred).map(class_map).fillna("Desconhecido").to_numpy()
        )
        sub["risco_previsto"] = (
            pd.Series(class_pred).map(risco_map).fillna("Desconhecido").to_numpy()
        )

        try:
            proba = models["model_clf"].predict_proba(features_data)
            sub["probabilidade_prevista"] = np.max(proba, axis=1).round(3)
        except Exception:
            sub["probabilidade_prevista"] = np.nan

        dfs.append(sub)
        feature_reports.append(report)

    df_out = pd.concat(dfs, ignore_index=True)

    # [resto do c√≥digo igual...]

    return df_out, feature_reports  # Retorna tamb√©m os reports
```

#### **PRIORIDADE 4: Interface de Usu√°rio Melhorada**

**Exibir qualidade dos dados na UI:**

```python
# No Streamlit app, ap√≥s fazer previs√£o
df_pred, feature_reports = predict_lineup_basico_v2(df_lineup, live_data, porto_nome)

# Calcula score m√©dio de confian√ßa
avg_confidence = np.mean([r.confidence_score for r in feature_reports])

# Exibe indicador visual
if avg_confidence >= 80:
    st.success(f"üü¢ Qualidade dos Dados: ALTA ({avg_confidence:.0f}%)")
elif avg_confidence >= 60:
    st.warning(f"üü° Qualidade dos Dados: M√âDIA ({avg_confidence:.0f}%)")
else:
    st.error(f"üî¥ Qualidade dos Dados: BAIXA ({avg_confidence:.0f}%)")

# Mostra detalhes em expander
with st.expander("üìä Detalhes da Qualidade dos Dados"):
    for i, report in enumerate(feature_reports):
        st.write(f"**Grupo {i+1}:** {report.total_features} features")

        # Gr√°fico de pizza
        import plotly.graph_objects as go
        labels = [q.value.replace("_", " ").title() for q in report.quality_breakdown.keys()]
        values = list(report.quality_breakdown.values())
        fig = go.Figure(data=[go.Pie(labels=labels, values=values)])
        st.plotly_chart(fig, use_container_width=True)

        # Avisos
        if report.critical_issues:
            for issue in report.critical_issues:
                st.error(issue)
        if report.warnings:
            for warn in report.warnings:
                st.warning(warn)
```

---

## 3. Roadmap de Implementa√ß√£o

### **Fase 1: Corre√ß√µes Cr√≠ticas (1-2 dias)**
- [ ] Corrigir `navios_no_fundeio_na_chegada` com c√°lculo correto
- [ ] Implementar `carregar_tempo_medio_historico()` com valores reais por porto
- [ ] Corrigir `tempo_espera_ma5` para usar hist√≥rico
- [ ] Testar impacto nas previs√µes

### **Fase 2: Sistema de Valida√ß√£o (2-3 dias)**
- [ ] Implementar classes `FeatureQuality` e `FeatureReport`
- [ ] Criar fun√ß√£o `avaliar_qualidade_features()`
- [ ] Integrar valida√ß√£o em `predict_lineup_basico_v2()`
- [ ] Adicionar coluna `confianca_previsao` ao output
- [ ] Atualizar UI para mostrar indicadores de qualidade

### **Fase 3: Melhorar APIs (3-5 dias)**
- [ ] Garantir que dados de clima sejam sempre obtidos (Open-Meteo como fallback)
- [ ] Implementar `carregar_ais_features_por_data()` para usar dados AIS existentes
- [ ] Verificar funcionamento correto de features de mar√©
- [ ] Adicionar logging para rastrear quando APIs falham
- [ ] Criar script de teste para validar todas as APIs

### **Fase 4: Modelos Simplificados (2-3 semanas - FUTURO)**
- [ ] Analisar import√¢ncia de features nos modelos atuais (SHAP, feature importance)
- [ ] Identificar top 15-20 features mais importantes
- [ ] Re-treinar modelos "light" usando apenas essas features
- [ ] Comparar performance: modelo completo vs light
- [ ] Se performance for similar (< 10% de degrada√ß√£o), substituir modelos

### **Fase 5: Valida√ß√£o Online (cont√≠nuo)**
- [ ] Salvar previs√µes feitas pelo app em banco de dados
- [ ] Comparar previs√µes com realidade ap√≥s alguns dias
- [ ] Calcular MAE real em produ√ß√£o
- [ ] Identificar casos onde modelo erra sistematicamente
- [ ] Refinar modelos com feedback do mundo real

---

## 4. Exemplo de Uso Ap√≥s Corre√ß√µes

### **Antes (Situa√ß√£o Atual):**
```
Usu√°rio carrega lineup ‚Üí App preenche 49 features com defaults ‚Üí
Modelo prev√™ 72h ‚Üí Usu√°rio n√£o sabe que previs√£o √© baseada 87% em defaults
```

### **Depois (Proposta):**
```
Usu√°rio carrega lineup ‚Üí App tenta obter dados de APIs ‚Üí
APIs dispon√≠veis: Clima ‚úÖ, AIS ‚ùå, Economia ‚úÖ, Mar√© ‚úÖ ‚Üí
App calcula features cr√≠ticas corretamente ‚Üí
Sistema avalia qualidade: 68% (M√âDIA) ‚Üí
Modelo prev√™ 72h ¬± 38h ‚Üí
UI mostra: "üü° Confian√ßa M√âDIA (68%) - Dados AIS indispon√≠veis"
```

---

## 5. Alternativa: Modelos Simplificados

Se as corre√ß√µes acima n√£o forem suficientes, considerar re-treinar modelos com apenas **features dispon√≠veis**:

### **Features M√≠nimas Recomendadas (15 features):**

```python
FEATURES_MINIMAS = [
    # Do lineup (5)
    "nome_porto",
    "nome_terminal",
    "natureza_carga",
    "movimentacao_total_toneladas",
    "mes",

    # Calculadas corretamente (3)
    "navios_no_fundeio_na_chegada",  # ‚Üê CORRIGIDO
    "navios_na_fila_7d",
    "porto_tempo_medio_historico",   # ‚Üê CORRIGIDO

    # Clima essencial (3)
    "temp_media_dia",
    "precipitacao_dia",
    "vento_rajada_max_dia",

    # Contexto (4)
    "dia_semana",
    "dia_do_ano",
    "periodo_safra",
    "flag_soja",  # ou flag_milho, dependendo do perfil
]
```

**Vantagens:**
- ‚úÖ Todas as features s√£o obt√≠veis de forma confi√°vel
- ‚úÖ Menos depend√™ncia de APIs externas
- ‚úÖ Previs√µes mais explic√°veis
- ‚úÖ Mais r√°pido para infer√™ncia

**Desvantagens:**
- ‚ùå Requer re-treino completo dos modelos
- ‚ùå Pode perder precis√£o (precisa validar)
- ‚ùå Perde contexto de mar√©, AIS, economia

**Recomenda√ß√£o:** Implementar Fases 1-3 primeiro, depois avaliar se modelos simplificados s√£o necess√°rios.

---

## 6. M√©tricas de Sucesso

### **Curto Prazo (ap√≥s Fases 1-2):**
- [ ] Score de confian√ßa m√©dio > 60% nas previs√µes
- [ ] 0% de features cr√≠ticas com valores fixos errados
- [ ] 100% das previs√µes t√™m indicador de qualidade vis√≠vel na UI
- [ ] Redu√ß√£o de 50% nos casos de "previs√£o n√£o confi√°vel"

### **M√©dio Prazo (ap√≥s Fase 3):**
- [ ] Score de confian√ßa m√©dio > 75% nas previs√µes
- [ ] Dados de clima dispon√≠veis em 95%+ dos casos (via fallback)
- [ ] Dados AIS dispon√≠veis em 50%+ dos casos (para portos principais)
- [ ] Usu√°rios reportam maior confian√ßa nas previs√µes

### **Longo Prazo (ap√≥s Fases 4-5):**
- [ ] MAE real em produ√ß√£o < 1.2x MAE de treino
- [ ] Score de confian√ßa m√©dio > 80%
- [ ] Feedback positivo de 80%+ dos usu√°rios
- [ ] Sistema identifica e alerta sobre casos de baixa confian√ßa

---

## 7. Conclus√£o

A proposta de corre√ß√£o √© **implementar melhorias incrementais** sem exigir re-treino imediato:

1. **Fase 1:** Corrigir c√°lculos cr√≠ticos (impacto imediato)
2. **Fase 2:** Adicionar sistema de valida√ß√£o (transpar√™ncia)
3. **Fase 3:** Melhorar obten√ß√£o de dados (qualidade)
4. **Fase 4:** Considerar modelos simplificados (se necess√°rio)
5. **Fase 5:** Valida√ß√£o cont√≠nua (melhoria cont√≠nua)

Esta abordagem permite **melhorias r√°pidas** (Fases 1-2 em menos de uma semana) e **prepara o terreno** para melhorias mais profundas no futuro.

**Pr√≥ximos passos imediatos:**
1. Revisar e aprovar esta proposta
2. Priorizar Fase 1 (corre√ß√µes cr√≠ticas)
3. Criar branch de desenvolvimento
4. Implementar corre√ß√µes com testes
5. Validar impacto antes de merge

---

**Fim da Proposta**
